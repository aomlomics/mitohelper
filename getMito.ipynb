{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getMito\n",
    "- GitHub page: https://github.com/shenjean/getMito\n",
    "- Wiki page: https://github.com/shenjean/getMito/wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This python script creates a dictionary from the nt.list file\n",
    "# The key is the NCBI accession number and the value is the gene description\n",
    "# This dictionary is then saved as a pickle named nt.pickle\n",
    "\n",
    "#!/usr/bin/python\n",
    "import pickle\n",
    "ntdict = {'Accession':'Gene description'}\n",
    "\n",
    "with open(\"nt.list\",'r') as f:\n",
    "    for line in f:\n",
    "        line = line.rstrip()\n",
    "        entry = line.split(\"\\t\")\n",
    "        fullacc=entry[0].split(\".\")\n",
    "        newentry={fullacc[0]:entry[1]} \n",
    "        ntdict.update(newentry)\n",
    "\n",
    "with open(\"nt.pickle\", 'wb') as handle:\n",
    "    pickle.dump(ntdict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Searching... ====\n",
      "LN610214\tNo hit found!\n",
      "LN610215\tNo hit found!\n",
      "LN610217\tNo hit found!\n",
      "LN610218\tNo hit found!\n",
      "LN610219\tNo hit found!\n",
      "LN610241\tNo hit found!\n",
      "LN610242\tNo hit found!\n",
      "LN610243\tNo hit found!\n",
      "LN610244\tNo hit found!\n",
      "==== Run complete! ===\n",
      "Total: 16 accession numbers\n",
      "No hits for 9 input accession numbers!\n"
     ]
    }
   ],
   "source": [
    "# This python script loads nt.pickle \n",
    "# Then, it matches MitoFish entries with keys (NCBI accession numbers) in the pickle\n",
    "# It takes ~24 minutes to match 616,999 MitoFish records to 57,377,397 NCBI GenBank records\n",
    "# cpupercent=101,cput=00:22:53,mem=34500088kb,ncpus=24,vmem=34845840kb,walltime=00:23:34\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "with open(\"nt.pickle\", 'rb') as handle:\n",
    "    NCBI = pickle.load(handle)\n",
    "\n",
    "outfile=\"mitofish.genes\"\n",
    "nohit=0\n",
    "count=0\n",
    "length=(len(NCBI))\n",
    "\n",
    "if path.exists(outfile) :\n",
    "    sys.exit(\"Error: Output file exists! Please rename output file and try again!\")\n",
    "\n",
    "output=open(outfile,'a')\n",
    "\n",
    "print(\"==== Searching... ====\")\n",
    "\n",
    "with open(\"mitofish.accession\",'r') as infile:\n",
    "    for inline in infile:\n",
    "        inline = inline.rstrip()\n",
    "        count +=1\n",
    "        if inline in NCBI:\n",
    "            output.write(\"%s\\t%s\\n\" % (inline,NCBI[inline]))\n",
    "        elif inline not in NCBI:\n",
    "            output.write(\"%s\\tNo hit found!\\n\" % inline)\n",
    "            print(\"%s\\tNo hit found!\" % inline)\n",
    "            nohit +=1\n",
    "            \n",
    "output.close()\n",
    "\n",
    "print (\"==== Run complete! ===\")\n",
    "print (\"Total: %d accession numbers\" % count)\n",
    "print (\"No hits for %d input accession numbers!\" % nohit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick up \"missing\" accession numbers \n",
    "\n",
    "In NCBI fasta files, records with duplicate sequences will be concatenated in the header line, e.g.\n",
    "\n",
    "```\n",
    ">LN610233.1 Chiloglanis anoterus mitochondrial partial D-loop, specimen voucher 68321_34LN610234.1 Chiloglanis anoterus mitochondrial partial D-loop, specimen voucher 68330_55\n",
    "```\n",
    "These will not be picked up by the python script above. First, let's extract the accession numbers with no hits into an output file named <b>nohit.accession</b>.\n",
    "```\n",
    "grep \"No hit\" mitofish.genes | awk -F \"\\t\" '{print $1}' | sed \"s/$/.[0-9]/g\" >nohit.accession\n",
    "```\n",
    "We added some regular expression patterns to the accession numbers with no hits so that the grep search is more specific. The output file <b>nohit.accession</b> looks like this:\n",
    "\n",
    "```\n",
    "LN610210.[0-9]\n",
    "LN610216.[0-9]\n",
    "LN610224.[0-9]\n",
    "LN610229.[0-9]\n",
    "LN610230.[0-9]\n",
    "LN610231.[0-9]\n",
    "LN610232.[0-9]\n",
    "LN610234.[0-9]\n",
    "LN610235.[0-9]\n",
    "```\n",
    "We will also extract the hits from the python search for later use. Output file is <b>hit.list</b>:\n",
    "```\n",
    "grep -v \"No hit\" mitofish.genes >hit.list\n",
    "```\n",
    "\n",
    "Next, split up the reference file (<b>nt.genenames</b> generated in previous step) into smaller chunks of 1 million lines each. Each split file will have the prefix x followed by a number e.g. x00, x01\n",
    "\n",
    "```\n",
    "cd NCBI\n",
    "split -d -l 1000000 nt.genenames\n",
    "cd ..\n",
    "```\n",
    "\n",
    "For each accession number with no hit, search each chunk of nt.genenames for matches using all processors (-P 0). -n 1 specifies the number of argument to pass per command line. This takes ~39 hours to run for 144,308 accession numbers.\n",
    "\n",
    "```\n",
    "for id in $(cat nohit.accession)\n",
    "do\n",
    "string=`ls NCBI/x* | xargs -n 1 -P 0 grep $id`\n",
    "echo \"$id%$string\" >>nohit.genes\n",
    "done\n",
    "```\n",
    "Output file is <b>nohit.genes</b>. First, let's clean up the output file by removing non-specific matches and removing the regular expression patterns following the accession numbers:\n",
    "\n",
    "```\n",
    "grep -P '\\t' nohit.genes | sed \"s/.\\[0\\-9\\]//g\" >nohit.genes.clean\n",
    "```\n",
    "\n",
    "Now, combine <b>hit.list</b> (accession numbers with exact matches with NCBI accession numbers) with <b>nohit.genes.clean</b> (accession numbers with duplicated sequences). The output file will be <b>mitofish.hit.list</b>:\n",
    "```\n",
    "cat hit.list nohit.genes.clean >mitofish.hit.list\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subspecies\n",
      "pysub\n",
      "mitofish.ref.tsv\n",
      "=== Searching user query #1 ===\n",
      "Query:Histioteuthis celetaria celetaria\tLevel:subspecies\t# Hits:0\n",
      "Query:Histioteuthis celetaria\tLevel:species\t# Hits:0\n",
      "Query:Histioteuthis\tLevel:genus\t# Hits:0\n",
      "=== Searching user query #2 ===\n",
      "Query:Histioteuthis corona corona\tLevel:subspecies\t# Hits:0\n",
      "Query:Histioteuthis corona\tLevel:species\t# Hits:0\n",
      "Duplicate query: Genus Histioteuthis has already been processed.\n",
      "=== Searching user query #3 ===\n",
      "Query:Stomias boa boa\tLevel:subspecies\t# Hits:0\n",
      "Query:Stomias boa\tLevel:species\t# Hits:28\n",
      "Query:Stomias\tLevel:genus\t# Hits:86\n",
      "=== Searching user query #4 ===\n",
      "Query:Lampadena urophaos atlantica\tLevel:subspecies\t# Hits:0\n",
      "Query:Lampadena urophaos\tLevel:species\t# Hits:13\n",
      "Query:Lampadena\tLevel:genus\t# Hits:63\n",
      "=== Searching user query #5 ===\n",
      "Query:Notoscopelus elongatus kroyeri\tLevel:subspecies\t# Hits:3\n",
      "Query:Notoscopelus elongatus\tLevel:species\t# Hits:18\n",
      "Query:Notoscopelus\tLevel:genus\t# Hits:64\n",
      "=== Searching user query #6 ===\n",
      "Query:Scopelogadus mizolepis mizolepis\tLevel:subspecies\t# Hits:0\n",
      "Query:Scopelogadus mizolepis\tLevel:species\t# Hits:33\n",
      "Query:Scopelogadus\tLevel:genus\t# Hits:52\n",
      "=== Searching user query #7 ===\n",
      "Duplicate query: Species Stomias boa boa has already been processed.\n",
      "Duplicate query: Species Stomias boa has already been processed.\n",
      "Duplicate query: Genus Stomias has already been processed.\n",
      "=== Searching user query #8 ===\n",
      "Query:Abraliopsis pfefferi\tLevel:species\t# Hits:0\n",
      "Query:Abraliopsis\tLevel:genus\t# Hits:0\n",
      "=== Searching user query #9 ===\n",
      "Query:Ahliesaurus berryi\tLevel:species\t# Hits:2\n",
      "Query:Ahliesaurus\tLevel:genus\t# Hits:2\n",
      "=== Searching user query #10 ===\n",
      "Query:Alepisaurus ferox\tLevel:species\t# Hits:32\n",
      "Query:Alepisaurus\tLevel:genus\t# Hits:35\n",
      "=== Searching user query #11 ===\n",
      "Query:Amphitretus pelagicus\tLevel:species\t# Hits:0\n",
      "Query:Amphitretus\tLevel:genus\t# Hits:0\n",
      "=== Searching user query #12 ===\n",
      "Query:Anoplogaster cornuta\tLevel:species\t# Hits:48\n",
      "Query:Anoplogaster\tLevel:genus\t# Hits:48\n",
      "=== Searching user query #13 ===\n",
      "Query:Anotopterus pharao\tLevel:species\t# Hits:9\n",
      "Query:Anotopterus\tLevel:genus\t# Hits:13\n",
      "=== Searching user query #14 ===\n",
      "Query:Argyropelecus aculeatus\tLevel:species\t# Hits:29\n",
      "Query:Argyropelecus\tLevel:genus\t# Hits:105\n",
      "=== Searching user query #15 ===\n",
      "Query:Argyropelecus affinis\tLevel:species\t# Hits:13\n",
      "Duplicate query: Genus Argyropelecus has already been processed.\n",
      "=== Searching user query #16 ===\n",
      "Query:Argyropelecus gigas\tLevel:species\t# Hits:23\n",
      "Duplicate query: Genus Argyropelecus has already been processed.\n",
      "=== Searching user query #17 ===\n",
      "Query:Argyropelecus hemigymnus\tLevel:species\t# Hits:23\n",
      "Duplicate query: Genus Argyropelecus has already been processed.\n",
      "=== Searching user query #18 ===\n",
      "Query:Argyropelecus olfersii\tLevel:species\t# Hits:3\n",
      "Duplicate query: Genus Argyropelecus has already been processed.\n",
      "=== Searching user query #19 ===\n",
      "Query:Argyropelecus sladeni\tLevel:species\t# Hits:9\n",
      "Duplicate query: Genus Argyropelecus has already been processed.\n",
      "=== Searching user query #20 ===\n",
      "Query:Aristostomias xenostoma\tLevel:species\t# Hits:3\n",
      "Query:Aristostomias\tLevel:genus\t# Hits:22\n",
      "=== Searching user query #21 ===\n",
      "Query:Astronesthes atlanticus\tLevel:species\t# Hits:0\n",
      "Query:Astronesthes\tLevel:genus\t# Hits:48\n",
      "=== Searching user query #22 ===\n",
      "Query:Astronesthes gemmifer\tLevel:species\t# Hits:2\n",
      "Duplicate query: Genus Astronesthes has already been processed.\n",
      "=== Searching user query #23 ===\n",
      "Query:Astronesthes leucopogon\tLevel:species\t# Hits:0\n",
      "Duplicate query: Genus Astronesthes has already been processed.\n",
      "=== Searching user query #24 ===\n",
      "Query:Astronesthes micropogon\tLevel:species\t# Hits:0\n",
      "Duplicate query: Genus Astronesthes has already been processed.\n",
      "==== Run complete! ===\n",
      "Accession numbers of genus hits and description saved in pysub_genus.hits.tsv\n",
      "Accession numbers of subspecies hits and description saved in pysub_species.hits.tsv\n",
      "Accession numbers of subspecies hits and description saved in pysub_subspecies.hits.tsv\n"
     ]
    }
   ],
   "source": [
    "# From a user-provided list of genera/species/subspecies, this script extracts the corresponding GenBank accession numbers \n",
    "# and gene names of their 12S rRNA sequences or mitochondrial sequences, if available.\n",
    "\n",
    "# This script is interactive and takes 3 inputs, in the following order:\n",
    "# 1) Input file name with extension (e.g. input.txt)\n",
    "# 2) Output file prefix for output files: <prefix>_genus.hits.tsv, <prefix>_species.hits.tsv, <prefix>_exact.hits.tsv\n",
    "# 3) Reference database - either 12S.ref.tsv or mitofish.ref.tsv\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "# Get the 3 inputs from user\n",
    "\n",
    "input_file = input()\n",
    "ref=tuple(open(input_file,'r'))\n",
    "output_prefix = input()\n",
    "reference_file = input()\n",
    "\n",
    "\n",
    "\n",
    "# Throw an error message and exit if output file(s) already exist\n",
    "\n",
    "full_path=str(output_prefix+\"_subspecies.hits.tsv\")\n",
    "species_path=str(output_prefix+\"_species.hits.tsv\")\n",
    "genus_path=str(output_prefix+\"_genus.hits.tsv\")\n",
    "\n",
    "\n",
    "if path.exists(full_path) or path.exists(species_path) or path.exists(genus_path) :\n",
    "    sys.exit(\"Error: Output file exists! Please rename output file and try again!\")\n",
    "    \n",
    "# This function performs matching at the specified level and writes results to the corresponding output file\n",
    "# Output files are tab-separated with the following columns:\n",
    "# Query, taxonomic level, GenBank accession number, gene description\n",
    "\n",
    "def matchme(query,level):\n",
    "    count=0\n",
    "    outpath=str(output_prefix+\"_\"+level+\".hits.tsv\")\n",
    "    output=open(outpath,'a')\n",
    "    with open(reference_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if query in line:\n",
    "                    count += 1\n",
    "                    output.write(\"%s\\t%s\\t%s\" % (query,level,line))\n",
    "    output.close()\n",
    "    print(\"Query:%s\\tLevel:%s\\t# Hits:%d\" % (query,level,count))\n",
    "    return;\n",
    "\n",
    "# The while loop below goes through the input file line by line \n",
    "i = 0\n",
    "seen=set()\n",
    "\n",
    "while (i < len(ref)):\n",
    "    \n",
    "    # Split string in query into genus,species, and subspecies (if present)\n",
    "    taxa=str(ref[i]).rsplit()\n",
    "    fulltaxa=str(ref[i]).rsplit(\"\\n\")\n",
    "    fullquery=str(fulltaxa[0])\n",
    "    gquery=str(taxa[0])\n",
    "    \n",
    "    # Check if species string exist in query\n",
    "    if (len(taxa)>1):\n",
    "        squery=str(taxa[0]+\" \"+taxa[1])\n",
    "    \n",
    "    qcount = i+1\n",
    "    print (\"=== Searching user query #%d ===\" % qcount)\n",
    "\n",
    "# These if statements determine the level of matching (subspecies/species/genus) for each UNIQUE query \n",
    "    \n",
    "    if (fullquery==gquery):\n",
    "        if fullquery not in seen:\n",
    "            matchme(query=fullquery,level=\"genus\")\n",
    "            seen.add(fullquery)\n",
    "        else:\n",
    "            print(\"Duplicate warning: Genus %s has already been processed.\" % fullquery)\n",
    "        \n",
    "    elif (fullquery==squery):\n",
    "        if fullquery not in seen:\n",
    "            matchme(query=fullquery,level=\"species\")\n",
    "            seen.add(fullquery)\n",
    "        else:\n",
    "            print(\"Duplicate query: Species %s has already been processed.\" % fullquery)\n",
    "        if gquery not in seen:\n",
    "            matchme(query=gquery,level=\"genus\")\n",
    "            seen.add(gquery)\n",
    "        else:\n",
    "            print(\"Duplicate query: Genus %s has already been processed.\" % gquery)\n",
    "    \n",
    "    else:\n",
    "        if fullquery not in seen:\n",
    "            matchme(query=fullquery,level=\"subspecies\")\n",
    "            seen.add(fullquery)\n",
    "        else:\n",
    "            print(\"Duplicate query: Species %s has already been processed.\" % fullquery)\n",
    "        if squery not in seen:\n",
    "            matchme(query=squery,level=\"species\")\n",
    "            seen.add(squery)\n",
    "        else:\n",
    "            print(\"Duplicate query: Species %s has already been processed.\" % squery)\n",
    "        if gquery not in seen:\n",
    "            matchme(query=gquery,level=\"genus\")\n",
    "            seen.add(gquery)\n",
    "        else:\n",
    "            print(\"Duplicate query: Genus %s has already been processed.\" % gquery)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print (\"==== Run complete! ===\")\n",
    "\n",
    "# Check and report on the types of output files generated \n",
    "\n",
    "if path.exists(genus_path): \n",
    "    print (\"Accession numbers of genus hits and description saved in %s\" % genus_path)\n",
    "else:\n",
    "    print(\"No genus detected in input file.\")\n",
    "    \n",
    "if path.exists(species_path):\n",
    "    print (\"Accession numbers of subspecies hits and description saved in %s\" % species_path)\n",
    "else:\n",
    "    print(\"No species detected in input file.\")\n",
    "    \n",
    "    \n",
    "if path.exists(full_path):\n",
    "    print (\"Accession numbers of subspecies hits and description saved in %s\" % full_path)\n",
    "else:\n",
    "    print(\"No subspecies detected in input file.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioPython",
   "language": "python",
   "name": "biopython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
